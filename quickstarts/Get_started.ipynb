{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtVOlmDSHmh4"
      },
      "source": [
        "##### Random Forest deepfake detection\n",
        "\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install kagglehub scikit-learn scikit-image opencv-python scipy joblib matplotlib seaborn tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPTmuiZqBIV9",
        "outputId": "c879beb7-b37b-4cf7-983b-31cc503e2dbe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.6.1)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.12.12)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import joblib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, roc_auc_score\n",
        ")\n",
        "from skimage.feature import local_binary_pattern, hog\n",
        "from scipy import fftpack\n",
        "import kagglehub"
      ],
      "metadata": {
        "id": "3j9LrRBECK1Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "WORK_DIR = '/content/deepfake_detection'\n",
        "DATA_DIR = f'{WORK_DIR}/data'\n",
        "MODELS_DIR = f'{WORK_DIR}/models'\n",
        "RESULTS_DIR = f'{WORK_DIR}/results'\n",
        "\n",
        "\n",
        "# Create directories\n",
        "for directory in [WORK_DIR, DATA_DIR, MODELS_DIR, RESULTS_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "# Dataset configuration\n",
        "IMAGE_SIZE = (256, 256)\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# NOTE: Dataset is already split into Train/Validation/Test\n",
        "# use the pre-existing splits\n",
        "\n",
        "# Model configuration\n",
        "RF_N_ESTIMATORS = 100\n",
        "RF_MAX_DEPTH = 20\n",
        "USE_FEATURE_SELECTION = True\n",
        "N_FEATURES_TO_SELECT = 50\n",
        "\n",
        "print(\"✅ Configuration complete!\")\n",
        "print(f\"\\nWorking directory: {WORK_DIR}\")\n",
        "print(f\"Image size: {IMAGE_SIZE}\")\n",
        "print(f\"Random Forest trees: {RF_N_ESTIMATORS}\")\n",
        "print(f\"Feature selection: {USE_FEATURE_SELECTION}\")\n",
        "if USE_FEATURE_SELECTION:\n",
        "    print(f\"  Features to select: {N_FEATURES_TO_SELECT}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9UfFZ4GCPSl",
        "outputId": "7e629228-fac1-4504-e868-b15135d988bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuration complete!\n",
            "\n",
            "Working directory: /content/deepfake_detection\n",
            "Image size: (256, 256)\n",
            "Random Forest trees: 100\n",
            "Feature selection: True\n",
            "  Features to select: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "print(\"Please upload your kaggle.json file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Setup Kaggle credentials\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download dataset\n",
        "print(\"Downloading dataset...\")\n",
        "dataset_path = kagglehub.dataset_download(\"manjilkarki/deepfake-and-real-images\")\n",
        "print(f\"Dataset downloaded to: {dataset_path}\")\n",
        "\n",
        "# Explore dataset structure\n",
        "print(\"\\nDataset contents:\")\n",
        "for item in os.listdir(dataset_path):\n",
        "    item_path = os.path.join(dataset_path, item)\n",
        "    if os.path.isdir(item_path):\n",
        "        num_files = len(os.listdir(item_path))\n",
        "        print(f\"   {item}/ ({num_files} files)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "2GK8Pf4dCWUp",
        "outputId": "ea41b383-4813-4eaf-eabc-731d57b1254b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your kaggle.json file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-458ab09a-7ba0-4c65-a6a5-5ae0d534035a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-458ab09a-7ba0-4c65-a6a5-5ae0d534035a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading dataset...\n",
            "Using Colab cache for faster access to the 'deepfake-and-real-images' dataset.\n",
            "Dataset downloaded to: /kaggle/input/deepfake-and-real-images\n",
            "\n",
            "Dataset contents:\n",
            "   Dataset/ (3 files)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import time\n",
        "\n",
        "class FastFeatureExtractor:\n",
        "\n",
        "\n",
        "    def extract_features(self, image):\n",
        "        features = []\n",
        "\n",
        "        # === COLOR FEATURES (Fast) ===\n",
        "        for channel in cv2.split(image):\n",
        "            features.extend([\n",
        "                np.mean(channel),\n",
        "                np.std(channel),\n",
        "                np.min(channel),\n",
        "                np.max(channel),\n",
        "                np.percentile(channel, 25),\n",
        "                np.percentile(channel, 75),\n",
        "            ])\n",
        "\n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # === GRAYSCALE STATISTICS ===\n",
        "        features.extend([\n",
        "            np.mean(gray),\n",
        "            np.std(gray),\n",
        "            np.var(gray),\n",
        "            np.median(gray),\n",
        "        ])\n",
        "\n",
        "        # === FREQUENCY FEATURES (IMPORTANT!) ===\n",
        "        # DCT - catches compression artifacts (KEY for deepfakes)\n",
        "        dct = cv2.dct(np.float32(gray))\n",
        "        dct_low = dct[:32, :32]  # Use smaller region for speed\n",
        "        features.extend([\n",
        "            np.mean(dct_low),\n",
        "            np.std(dct_low),\n",
        "            np.max(dct_low),\n",
        "            np.min(dct_low),\n",
        "            np.median(dct_low),\n",
        "        ])\n",
        "\n",
        "        # FFT - frequency domain analysis\n",
        "        f_transform = np.fft.fft2(gray)\n",
        "        f_shift = np.fft.fftshift(f_transform)\n",
        "        magnitude = np.abs(f_shift)\n",
        "\n",
        "        # Radial frequency features\n",
        "        center = np.array(magnitude.shape) // 2\n",
        "        y, x = np.ogrid[:magnitude.shape[0], :magnitude.shape[1]]\n",
        "        r = np.sqrt((x - center[1])**2 + (y - center[0])**2)\n",
        "\n",
        "        for radius in [20, 50, 80]:\n",
        "            mask = (r >= radius-10) & (r < radius+10)\n",
        "            if np.sum(mask) > 0:\n",
        "                features.append(np.mean(magnitude[mask]))\n",
        "\n",
        "        # === TEXTURE FEATURES (IMPORTANT!) ===\n",
        "        # Simplified LBP\n",
        "        from skimage.feature import local_binary_pattern\n",
        "        radius = 2\n",
        "        n_points = 8 * radius\n",
        "        lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
        "\n",
        "        # LBP histogram (reduced bins for speed)\n",
        "        n_bins = 10\n",
        "        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins))\n",
        "        hist = hist.astype(float) / (hist.sum() + 1e-7)\n",
        "        features.extend(hist)\n",
        "\n",
        "        # === EDGE FEATURES ===\n",
        "        edges = cv2.Canny(gray, 100, 200)\n",
        "        features.append(np.sum(edges > 0) / edges.size)\n",
        "\n",
        "        # Gradient magnitude\n",
        "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "        gradient_mag = np.sqrt(sobelx**2 + sobely**2)\n",
        "        features.extend([\n",
        "            np.mean(gradient_mag),\n",
        "            np.std(gradient_mag),\n",
        "            np.max(gradient_mag),\n",
        "        ])\n",
        "\n",
        "        # === COLOUR CORRELATIONS ===\n",
        "        b, g, r = cv2.split(image)\n",
        "        features.append(np.corrcoef(b.flatten(), g.flatten())[0, 1])\n",
        "        features.append(np.corrcoef(g.flatten(), r.flatten())[0, 1])\n",
        "        features.append(np.corrcoef(r.flatten(), b.flatten())[0, 1])\n",
        "\n",
        "        return np.array(features, dtype=np.float32)\n",
        "\n",
        "    def extract_from_batch_vectorized(self, images):\n",
        "        batch_features = []\n",
        "        for img in images:\n",
        "            features = self.extract_features(img)\n",
        "            batch_features.append(features)\n",
        "        return np.array(batch_features, dtype=np.float32)\n",
        "\n",
        "def load_and_extract_folder_fast(folder_path, label, extractor,\n",
        "                                 img_size=(256, 256), chunk_size=5000):\n",
        "    if not os.path.exists(folder_path):\n",
        "        raise FileNotFoundError(f\"Folder not found: {folder_path}\")\n",
        "\n",
        "    image_files = [f for f in os.listdir(folder_path)\n",
        "                  if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
        "\n",
        "    total_images = len(image_files)\n",
        "    print(f\"Processing {total_images} images from {os.path.basename(folder_path)}...\")\n",
        "\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Process in large chunks\n",
        "    for i in tqdm(range(0, total_images, chunk_size)):\n",
        "        chunk_files = image_files[i:i+chunk_size]\n",
        "        chunk_images = []\n",
        "\n",
        "        # Load chunk\n",
        "        for img_file in chunk_files:\n",
        "            img_path = os.path.join(folder_path, img_file)\n",
        "            try:\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.resize(img, img_size)\n",
        "                    chunk_images.append(img)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        if chunk_images:\n",
        "            # Extract features from chunk\n",
        "            chunk_images = np.array(chunk_images)\n",
        "            chunk_features = extractor.extract_from_batch_vectorized(chunk_images)\n",
        "            chunk_labels = np.full(len(chunk_features), label)\n",
        "\n",
        "            all_features.append(chunk_features)\n",
        "            all_labels.append(chunk_labels)\n",
        "\n",
        "            # Clear memory\n",
        "            del chunk_images, chunk_features, chunk_labels\n",
        "            gc.collect()\n",
        "\n",
        "    # Combine all chunks\n",
        "    features = np.vstack(all_features)\n",
        "    labels = np.concatenate(all_labels)\n",
        "\n",
        "    del all_features, all_labels\n",
        "    gc.collect()\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "def load_split_fast(dataset_path, split_name, extractor, img_size=(256, 256)):\n",
        "    split_path = os.path.join(dataset_path, 'Dataset', split_name)\n",
        "    real_path = os.path.join(split_path, 'Real')\n",
        "    fake_path = os.path.join(split_path, 'Fake')\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Processing {split_name} Set\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    if not os.path.exists(real_path):\n",
        "        raise FileNotFoundError(f\"Real folder not found: {real_path}\")\n",
        "    if not os.path.exists(fake_path):\n",
        "        raise FileNotFoundError(f\"Fake folder not found: {fake_path}\")\n",
        "\n",
        "    # Process Real images\n",
        "    start = time.time()\n",
        "    print(\"Processing Real images...\")\n",
        "    X_real, y_real = load_and_extract_folder_fast(real_path, 0, extractor, img_size)\n",
        "    real_time = time.time() - start\n",
        "    print(f\"  Time: {real_time:.2f}s ({len(X_real)/real_time:.0f} images/sec)\")\n",
        "\n",
        "    # Process Fake images\n",
        "    start = time.time()\n",
        "    print(\"Processing Fake images...\")\n",
        "    X_fake, y_fake = load_and_extract_folder_fast(fake_path, 1, extractor, img_size)\n",
        "    fake_time = time.time() - start\n",
        "    print(f\"  Time: {fake_time:.2f}s ({len(X_fake)/fake_time:.0f} images/sec)\")\n",
        "\n",
        "    # Combine\n",
        "    X = np.vstack([X_real, X_fake])\n",
        "    y = np.concatenate([y_real, y_fake])\n",
        "\n",
        "    del X_real, X_fake, y_real, y_fake\n",
        "    gc.collect()\n",
        "\n",
        "    print(f\"\\n{split_name} Summary:\")\n",
        "    print(f\"  Total: {len(X)} samples | Features: {X.shape[1]}\")\n",
        "    print(f\"  Real: {np.sum(y==0)} | Fake: {np.sum(y==1)}\")\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# ========== MAIN PROCESSING ==========\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ULTRA-FAST FEATURE EXTRACTION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Initialize fast extractor\n",
        "extractor = FastFeatureExtractor()\n",
        "\n",
        "# Test on a few images first\n",
        "print(\"\\nTesting extractor speed...\")\n",
        "test_img = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n",
        "start = time.time()\n",
        "for _ in range(100):\n",
        "    _ = extractor.extract_features(test_img)\n",
        "test_time = time.time() - start\n",
        "print(f\"Speed test: {100/test_time:.0f} images/second per core\")\n",
        "\n",
        "# Process all splits\n",
        "splits_to_try = {\n",
        "    'train': ['Train', 'train'],\n",
        "    'val': ['Validation', 'validation', 'Val', 'val'],\n",
        "    'test': ['Test', 'test']\n",
        "}\n",
        "\n",
        "def load_split_safe(base_path, split_variations, extractor):\n",
        "    for variation in split_variations:\n",
        "        try:\n",
        "            return load_split_fast(base_path, variation, extractor)\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "    raise FileNotFoundError(f\"Could not find split\")\n",
        "\n",
        "# Process each split with timing\n",
        "total_start = time.time()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PROCESSING TRAINING SET\")\n",
        "print(\"=\"*70)\n",
        "X_train, y_train = load_split_safe(dataset_path, splits_to_try['train'], extractor)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PROCESSING VALIDATION SET\")\n",
        "print(\"=\"*70)\n",
        "X_val, y_val = load_split_safe(dataset_path, splits_to_try['val'], extractor)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PROCESSING TEST SET\")\n",
        "print(\"=\"*70)\n",
        "X_test, y_test = load_split_safe(dataset_path, splits_to_try['test'], extractor)\n",
        "\n",
        "total_time = time.time() - total_start\n",
        "total_samples = len(X_train) + len(X_val) + len(X_test)\n",
        "\n",
        "print(f\"\\n⏱️  Total extraction time: {total_time/60:.2f} minutes\")\n",
        "print(f\"⚡ Speed: {total_samples/total_time:.0f} images/second\")\n",
        "\n",
        "# ========== FEATURE ENGINEERING ==========\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FEATURE ENGINEERING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Normalize\n",
        "print(\"Normalizing features...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Normalized\")\n",
        "\n",
        "# Feature selection\n",
        "if USE_FEATURE_SELECTION and N_FEATURES_TO_SELECT < X_train_scaled.shape[1]:\n",
        "    print(f\"\\nSelecting top {N_FEATURES_TO_SELECT} features...\")\n",
        "    selector = SelectKBest(score_func=f_classif, k=N_FEATURES_TO_SELECT)\n",
        "    X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
        "    X_val_selected = selector.transform(X_val_scaled)\n",
        "    X_test_selected = selector.transform(X_test_scaled)\n",
        "    print(f\"Selected: {X_train_scaled.shape[1]} → {X_train_selected.shape[1]}\")\n",
        "else:\n",
        "    X_train_selected = X_train_scaled\n",
        "    X_val_selected = X_val_scaled\n",
        "    X_test_selected = X_test_scaled\n",
        "\n",
        "# Clean up\n",
        "del X_train, X_val, X_test, X_train_scaled, X_val_scaled, X_test_scaled\n",
        "gc.collect()\n",
        "\n",
        "# ========== SUMMARY ==========\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"READY FOR TRAINING\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nTotal samples: {total_samples}\")\n",
        "print(f\"Features per sample: {X_train_selected.shape[1]}\")\n",
        "print(f\"Extraction time: {total_time/60:.2f} minutes\")\n",
        "print(f\"Processing speed: {total_samples/total_time:.0f} images/sec\")\n",
        "\n",
        "print(f\"\\nData splits:\")\n",
        "print(f\"  Train: {len(X_train_selected):>6} ({len(X_train_selected)/total_samples*100:.1f}%)\")\n",
        "print(f\"  Val:   {len(X_val_selected):>6} ({len(X_val_selected)/total_samples*100:.1f}%)\")\n",
        "print(f\"  Test:  {len(X_test_selected):>6} ({len(X_test_selected)/total_samples*100:.1f}%)\")\n",
        "\n",
        "print(\"\\nFeature extraction complete - ready for model training!\")\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0MNRXA_Eobk",
        "outputId": "d768138d-9c0d-472f-9dc4-53e2d4f8b162"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ULTRA-FAST FEATURE EXTRACTION\n",
            "======================================================================\n",
            "\n",
            "Testing extractor speed...\n",
            "Speed test: 20 images/second per core\n",
            "\n",
            "======================================================================\n",
            "PROCESSING TRAINING SET\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Processing Train Set\n",
            "======================================================================\n",
            "Processing Real images...\n",
            "Processing 70001 images from Real...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [54:42<00:00, 218.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Time: 3283.45s (21 images/sec)\n",
            "Processing Fake images...\n",
            "Processing 70001 images from Fake...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [55:39<00:00, 222.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Time: 3339.59s (21 images/sec)\n",
            "\n",
            "Train Summary:\n",
            "  Total: 140002 samples | Features: 47\n",
            "  Real: 70001 | Fake: 70001\n",
            "\n",
            "======================================================================\n",
            "PROCESSING VALIDATION SET\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Processing Validation Set\n",
            "======================================================================\n",
            "Processing Real images...\n",
            "Processing 19787 images from Real...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [15:57<00:00, 239.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Time: 958.24s (21 images/sec)\n",
            "Processing Fake images...\n",
            "Processing 19641 images from Fake...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [15:52<00:00, 238.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Time: 952.60s (21 images/sec)\n",
            "\n",
            "Validation Summary:\n",
            "  Total: 39428 samples | Features: 47\n",
            "  Real: 19787 | Fake: 19641\n",
            "\n",
            "======================================================================\n",
            "PROCESSING TEST SET\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Processing Test Set\n",
            "======================================================================\n",
            "Processing Real images...\n",
            "Processing 5413 images from Real...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [04:18<00:00, 129.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Time: 258.22s (21 images/sec)\n",
            "Processing Fake images...\n",
            "Processing 5492 images from Fake...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [04:25<00:00, 132.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Time: 265.80s (21 images/sec)\n",
            "\n",
            "Test Summary:\n",
            "  Total: 10905 samples | Features: 47\n",
            "  Real: 5413 | Fake: 5492\n",
            "\n",
            "⏱️  Total extraction time: 150.97 minutes\n",
            "⚡ Speed: 21 images/second\n",
            "\n",
            "======================================================================\n",
            "FEATURE ENGINEERING\n",
            "======================================================================\n",
            "Normalizing features...\n",
            "Normalized\n",
            "\n",
            "======================================================================\n",
            "READY FOR TRAINING\n",
            "======================================================================\n",
            "\n",
            "Total samples: 190335\n",
            "Features per sample: 47\n",
            "Extraction time: 150.97 minutes\n",
            "Processing speed: 21 images/sec\n",
            "\n",
            "Data splits:\n",
            "  Train: 140002 (73.6%)\n",
            "  Val:    39428 (20.7%)\n",
            "  Test:   10905 (5.7%)\n",
            "\n",
            "Feature extraction complete - ready for model training!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING IMPROVED RANDOM FOREST\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Better hyperparameters for deepfake detection\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=500,          # More trees = more stable\n",
        "    max_depth=12,              # SHALLOWER trees (was 20)\n",
        "    min_samples_split=20,      # Need MORE samples to split (was 2)\n",
        "    min_samples_leaf=10,       # LARGER leaves (was 1)\n",
        "    max_features='sqrt',       # Use sqrt(n) features per tree\n",
        "    max_samples=0.7,           # Use only 70% of data per tree (bootstrap)\n",
        "    class_weight='balanced',   # Handle class imbalance\n",
        "    bootstrap=True,\n",
        "    oob_score=True,            # Out-of-bag score for validation\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(f\"Model configuration:\")\n",
        "print(f\"  Trees: {model.n_estimators}\")\n",
        "print(f\"  Max depth: {model.max_depth}\")\n",
        "print(f\"  Class weight: balanced\")\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "model.fit(X_train_selected, y_train)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nTraining complete in {training_time:.2f} seconds\")\n",
        "\n",
        "# Training accuracy\n",
        "train_pred = model.predict(X_train_selected)\n",
        "train_accuracy = accuracy_score(y_train, train_pred)\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in6vzBuan_AW",
        "outputId": "bc01fc6e-3bfb-4503-a14e-e51b55c56eb0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING IMPROVED RANDOM FOREST\n",
            "======================================================================\n",
            "Model configuration:\n",
            "  Trees: 500\n",
            "  Max depth: 12\n",
            "  Class weight: balanced\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   32.9s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  5.9min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training complete in 366.67 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    6.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.7527 (75.27%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done 500 out of 500 | elapsed:    7.0s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X, y, dataset_name=\"Test\"):\n",
        "    \"\"\"Evaluate model and print metrics\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"{dataset_name} Set Evaluation\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X)\n",
        "    y_pred_proba = model.predict_proba(X)[:, 1]\n",
        "\n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    precision = precision_score(y, y_pred)\n",
        "    recall = recall_score(y, y_pred)\n",
        "    f1 = f1_score(y, y_pred)\n",
        "    auc = roc_auc_score(y, y_pred_proba)\n",
        "\n",
        "    print(f\"\\nMetrics:\")\n",
        "    print(f\"  Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall:    {recall:.4f}\")\n",
        "    print(f\"  F1-Score:  {f1:.4f}\")\n",
        "    print(f\"  ROC-AUC:   {auc:.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y, y_pred)\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(f\"  TN (Real→Real): {cm[0,0]:>5}  |  FP (Real→Fake): {cm[0,1]:>5}\")\n",
        "    print(f\"  FN (Fake→Real): {cm[1,0]:>5}  |  TP (Fake→Fake): {cm[1,1]:>5}\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'auc': auc,\n",
        "        'confusion_matrix': cm,\n",
        "        'y_pred': y_pred,\n",
        "        'y_pred_proba': y_pred_proba\n",
        "    }\n",
        "\n",
        "# Evaluate on validation and test sets\n",
        "print(\"\\n=== Model Evaluation ===\")\n",
        "val_metrics = evaluate_model(model, X_val_selected, y_val, \"Validation\")\n",
        "test_metrics = evaluate_model(model, X_test_selected, y_test, \"Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WrfQPXAo_vl",
        "outputId": "306955db-eede-4dce-b9ab-41669b9091d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Model Evaluation ===\n",
            "\n",
            "============================================================\n",
            "Validation Set Evaluation\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=2)]: Done 500 out of 500 | elapsed:    1.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=2)]: Done 500 out of 500 | elapsed:    1.7s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metrics:\n",
            "  Accuracy:  0.7091 (70.91%)\n",
            "  Precision: 0.6711\n",
            "  Recall:    0.8161\n",
            "  F1-Score:  0.7365\n",
            "  ROC-AUC:   0.7905\n",
            "\n",
            "Confusion Matrix:\n",
            "  TN (Real→Real): 11930  |  FP (Real→Fake):  7857\n",
            "  FN (Fake→Real):  3612  |  TP (Fake→Fake): 16029\n",
            "\n",
            "============================================================\n",
            "Test Set Evaluation\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 500 out of 500 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metrics:\n",
            "  Accuracy:  0.5644 (56.44%)\n",
            "  Precision: 0.5475\n",
            "  Recall:    0.7788\n",
            "  F1-Score:  0.6430\n",
            "  ROC-AUC:   0.5837\n",
            "\n",
            "Confusion Matrix:\n",
            "  TN (Real→Real):  1878  |  FP (Real→Fake):  3535\n",
            "  FN (Fake→Real):  1215  |  TP (Fake→Fake):  4277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 500 out of 500 | elapsed:    0.5s finished\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Get_started.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}